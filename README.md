# Natural Language Processing

## Tokenization
Break up the text into component pieces called "tokens". They are the <b>basic building block</b> of a document object.

## Stemming
Defines a keyword and then find variations to find relations between them. Focus on word reduction there are two main approaches: Porter & Snowball.

## Lemmatization
## Stop Words
## Part of speech "POS"
## Named Entity Recognition
## Feature Extraction
## Semantic Analysis
## Topic Modelling
## Non Negative Matrix Factorization

